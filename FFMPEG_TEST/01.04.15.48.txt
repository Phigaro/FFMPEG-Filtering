///> Include FFMpeg
#define _CRT_SECURE_NO_DEPRECATE
#pragma warning(disable:4996)

#include <iostream>

///> Include FFMpeg
extern "C" {
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libavutil/avutil.h>
#include <libswscale/swscale.h>
#include <libavformat/avio.h>
#include <libavutil/opt.h>

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>
#include <libavutil/opt.h>
#include <libavutil/mathematics.h>
#include <libswscale/swscale.h>
#include <libswresample/swresample.h>
}
#include "FileWriter.h"

///> Library Link On Windows System
#pragma comment( lib, "avformat.lib" )   
#pragma comment( lib, "avutil.lib" )
#pragma comment( lib, "avcodec.lib" )
//전역
AVCodec* codec;
bool bPrint = false;
AVFormatContext *pFmtCtx = NULL;
//http://www.ithinknext.com/mydata/board/files/F201308021823010.mp4
const char *szFilePath = "./Test_Video.mkv";
static void write_ascii_frame(const char *szFileName, const AVFrame *pVframe);
static AVFormatContext *fmt_ctx = NULL;
static AVCodecContext *dec_ctx = NULL;
static int vst_idx = -1;
AVFormatContext *oc;
AVOutputFormat *fmt;
AVStream *audio_st, *video_st;
double audio_pts, video_pts;
AVOutputFormat *avOutputFormat;
const char *outputfilename = "outputfile.mkv";

/* 5 seconds stream duration */
#define STREAM_DURATION   200.0
#define STREAM_FRAME_RATE 25
/* 25 images/s */
#define STREAM_NB_FRAMES  ((int)(STREAM_DURATION * STREAM_FRAME_RATE))
#define STREAM_PIX_FMT    AV_PIX_FMT_YUV420P
/* default pix_fmt */
static int sws_flags = SWS_BICUBIC;

/* Add an output stream. */
static AVStream *add_stream(AVFormatContext *oc, AVCodec **codec, enum AVCodecID codec_id)
{
	AVCodecContext *c;
	AVStream *st;
	/* find the encoder */
	*codec = avcodec_find_encoder(codec_id);
	if (!(*codec))
	{
		fprintf(stderr, "Could not find encoder for '%s'\n", avcodec_get_name(codec_id)
		);        exit(1);
	}
	st = avformat_new_stream(oc, *codec);
	if (!st) {
		fprintf(stderr, "Could not allocate stream\n");
		exit(1);
	}    st->id = oc->nb_streams - 1;
	c = st->codec;
	switch ((*codec)->type)
	{
	case AVMEDIA_TYPE_AUDIO:
		c->sample_fmt = AV_SAMPLE_FMT_FLTP;
		c->bit_rate = 64000;
		c->sample_rate = 44100;
		c->channels = 2;
		break;
	case AVMEDIA_TYPE_VIDEO:

		c->codec_id = codec_id;
		c->bit_rate = 400000;
		/* Resolution must be a multiple of two. */
		c->width = 352;
		c->height = 288;
		/* timebase: This is the fundamental unit of time (in seconds) in terms
		* of which frame timestamps are represented. For fixed-fps content,
		* timebase should be 1/framerate and timestamp increments should be
		* identical to 1. */
		c->time_base.den = STREAM_FRAME_RATE;
		c->time_base.num = 1;
		c->gop_size = 12; /* emit one intra frame every twelve frames at most */
		c->pix_fmt = STREAM_PIX_FMT;
		if (c->codec_id == AV_CODEC_ID_MPEG2VIDEO) {
			/* just for testing, we also add B frames */
			c->max_b_frames = 2;
		}
		if (c->codec_id == AV_CODEC_ID_MPEG1VIDEO) {
			/* Needed to avoid using macroblocks in which some coeffs overflow.
			* This does not happen with normal video, it just happens here as
			* the motion of the chroma plane does not match the luma plane. */
			c->mb_decision = 2;
		}
		break;
	default:
		break;
	}    /* Some formats want stream headers to be separate. */
	if (oc->oformat->flags & AVFMT_GLOBALHEADER)
		c->flags |= CODEC_FLAG_GLOBAL_HEADER;
	return st;
}

/**************************************************************//* video output */
static AVFrame *frame;
static AVPicture src_picture, dst_picture;
static int frame_count;
static void open_video(AVFormatContext *oc, AVCodec *codec, AVStream *st)
{
	int ret;
	AVCodecContext *c = st->codec;
	/* open the codec */
	ret = avcodec_open2(c, codec, NULL);
	if (ret < 0) {

		//fprintf(stderr, "Could not open video codec: %s\n", av_err2str(ret));
		//fprintf(stderr, "Could not open video codec: %s\n", av_err2str(ret));
		exit(1);
	}    /* allocate and init a re-usable frame */
	frame = avcodec_alloc_frame();
	if (!frame) {
		fprintf(stderr, "Could not allocate video frame\n"
		);
		exit(1);
	}
	/* Allocate the encoded raw picture. */
	ret = avpicture_alloc(&dst_picture, c->pix_fmt, c->width, c->height);
	if (ret < 0) {
		//fprintf(stderr, "Could not allocate picture: %s\n", av_err2str(ret));
		exit(1);
	}
	/* If the output format is not YUV420P, then a temporary YUV420P
	* picture is needed too. It is then converted to the required
	* output format. */
	if (c->pix_fmt != AV_PIX_FMT_YUV420P) {
		ret = avpicture_alloc(&src_picture, AV_PIX_FMT_YUV420P, c->width, c->height
		);
		if (ret < 0) {
			//fprintf(stderr, "Could not allocate temporary picture: %s\n", av_err2str(ret));
			exit(1);
		}
	}
	/* copy data and linesize picture pointers to frame */
	*((AVPicture *)frame) = dst_picture;
}
/* Prepare a dummy image. */
static void fill_yuv_image(AVPicture *pict, int frame_index, int width, int height)
{
	int x, y, i;
	i = frame_index;
	/* Y */
	for (y = 0; y < height; y++)
		for (x = 0; x < width; x++)
			pict->data[0][y * pict->linesize[0] + x] = x + y + i * 3; /* Cb and Cr */
	for (y = 0; y < height / 2; y++)
	{
		for (x = 0; x < width / 2; x++) {
			pict->data[1][y * pict->linesize[1] + x] = 128 + y + i * 2;
			pict->data[2][y * pict->linesize[2] + x] = 64 + x + i * 5;
		}
	}
}

static void write_video_frame(AVFormatContext *oc, AVStream *st)
{
	int ret;    static struct SwsContext *sws_ctx;
	AVCodecContext *c = st->codec;
	if (frame_count >= STREAM_NB_FRAMES) {
		/* No more frames to compress. The codec has a latency of a few         * frames if using B-frames, so we get the last frames by         * passing the same picture again. */
	}
	else {
		if (c->pix_fmt != AV_PIX_FMT_YUV420P) {
			/* as we only generate a YUV420P picture, we must convert it             * to the codec pixel format if needed */            if (!sws_ctx) { sws_ctx = sws_getContext(c->width, c->height, AV_PIX_FMT_YUV420P, c->width, c->height, c->pix_fmt, sws_flags, NULL, NULL, NULL);                if (!sws_ctx) { fprintf(stderr, "Could not initialize the conversion context\n");                    exit(1); } }            fill_yuv_image(&src_picture, frame_count, c->width, c->height);            sws_scale(sws_ctx, (const uint8_t * const *)src_picture.data, src_picture.linesize, 0, c->height, dst_picture.data, dst_picture.linesize);
		}
		else { fill_yuv_image(&dst_picture, frame_count, c->width, c->height); }
	}    if (oc->oformat->flags & AVFMT_RAWPICTURE) {        /* Raw video case - directly store the picture in the packet */        AVPacket pkt;        av_init_packet(&pkt);        pkt.flags |= AV_PKT_FLAG_KEY;        pkt.stream_index = st->index;        pkt.data = dst_picture.data[0];        pkt.size = sizeof(AVPicture);        ret = av_interleaved_write_frame(oc, &pkt); }
	else {
		AVPacket pkt = { 0 };
		int got_packet;
		av_init_packet(&pkt);
		/* encode the image */
		ret = avcodec_encode_video2(c, &pkt, frame, &got_packet);
		if (ret < 0) {
			//fprintf(stderr, "Error encoding video frame: %s\n", av_err2str(ret));
			exit(1);
		}
		/* If size is zero, it means the image was buffered. */
		if (!ret && got_packet && pkt.size) {
			pkt.stream_index = st->index;
			/* Write the compressed frame to the media file. */
			ret = av_interleaved_write_frame(oc, &pkt);
		}
		else {
			ret = 0;
		}
	}    if (ret != 0) {
		//fprintf(stderr, "Error while writing video frame: %s\n", av_err2str(ret));
		exit(1);
	}    frame_count++;
}

static void close_video(AVFormatContext *oc, AVStream *st) {
	avcodec_close(st->codec);
	av_free(src_picture.data[0]);
	av_free(dst_picture.data[0]);
	av_free(frame);
}

void open_input_file()
{
	AVCodec *dec;
	avformat_open_input(&fmt_ctx, szFilePath, NULL, NULL);
	vst_idx = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, &dec, 0);
	dec_ctx = fmt_ctx->streams[vst_idx]->codec;
	avcodec_open2(dec_ctx, dec, NULL);
	std::cout << dec_ctx->codec->name;
}

void close_input_file()
{
	for (int i = 0; i < fmt_ctx->nb_streams; i++) {
		AVStream *st = fmt_ctx->streams[i];
		avcodec_close(st->codec);
	}
	avformat_close_input(&fmt_ctx);
}

void encode_video()
{
	AVPacket pkt, outpkt;
	AVFrame *frm;
	int got_frame, got_output;
	AVRational AVr = { 1,25 };
	AVCodec *enc;
	AVCodecContext *enc_ctx = NULL;
	dec_ctx->codec_id;
	enc = avcodec_find_encoder(AV_CODEC_ID_H261);

	enc_ctx = avcodec_alloc_context3(enc);

	enc_ctx->bit_rate = 400000;
	enc_ctx->width = 352;
	enc_ctx->height = 288;
	enc_ctx->time_base = AVr;
	//enc_ctx->gop_size = 10; /* emit one intra frame every ten frames */
	//enc_ctx->max_b_frames = 1;
	enc_ctx->pix_fmt = AV_PIX_FMT_YUV420P;

	av_opt_set(enc_ctx->priv_data, "preset", "fast", 0);
	av_opt_set(enc_ctx->priv_data, "profile", "baseline", 0);



	avcodec_open2(enc_ctx, enc, NULL);
	frm = av_frame_alloc();
	// 패킷을 순서대로 읽어옴
	while (av_read_frame(fmt_ctx, &pkt) >= 0) {
		// 해당 패킷이 비디오 스트림이면
		if (pkt.stream_index == vst_idx) {
			// avcodec_get_frame_defaults(frm);
			// 해당 패킷을 디코드함
			avcodec_decode_video2(dec_ctx, frm, &got_frame, &pkt);

			if (got_frame) {
				av_init_packet(&outpkt);
				outpkt.data = NULL;
				outpkt.size = 0;

				int ref;
				write_ascii_frame("output.txt", frm);
				got_output = 1;
				ref = avcodec_encode_video2(enc_ctx, &outpkt, frm, &got_output);
				printf("encoder returned %d size of data\n", outpkt.size);
				if (ref < 0) {
					fprintf(stderr, "Error encoding frame\n");
					exit(1);
				}

				int write_ret;
				if (got_output) {
					/* write the compressed frame in the media file */
					//write_ret = av_write_frame(fmt_ctx, &outpkt);
					//if (write_ret < 0) {
					//	fprintf(stderr, "Error writing frame\n");
					//	exit(1);
					//}

					av_free_packet(&pkt);
				}
				else {
					printf("got_output false: %d", 100);
				}




				av_free_packet(&outpkt);
			}
		}
	}
	av_free_packet(&pkt);
	av_frame_free(&frm);
}


int main(void)
{


	///> Initialize libavformat and register all the muxers, demuxers and protocols.
	av_register_all();

	///> Do global initialization of network components.
	avformat_network_init();

	avOutputFormat = av_guess_format(NULL, outputfilename, NULL);
	if (!avOutputFormat) {
		std::cout << "Could not deduce output format from file extension: using << MPEG.\n";
		avOutputFormat = av_guess_format("mpeg", NULL, NULL);
	}
	if (!avOutputFormat) {
		fprintf(stderr, "Could not find suitable output format\n");
		exit(1);
	}

	avOutputFormat->video_codec = AV_CODEC_ID_H261;

	oc = avformat_alloc_context();

	if (!oc) {
		fprintf(stderr, "메모리에러\n");
		exit(1);
	}
	oc->oformat = fmt;
	snprintf(oc->filename, sizeof(oc->filename), "%s", "output.mp4");
	open_input_file();

	encode_video();



	close_input_file();
	return 0;
}

static void write_ascii_frame(const char *szFileName, const AVFrame *frame)
{
	int x, y;
	uint8_t *p0, *p;
	const char arrAsciis[] = " .-+#";

	FILE* fp = fopen("ascii.txt", "w");
	if (fp) {
		/* Trivial ASCII grayscale display. */
		p0 = frame->data[0];
		for (y = 0; y < frame->height; y++) {
			p = p0;
			for (x = 0; x < frame->width; x++)
				putc(arrAsciis[*(p++) / 52], fp);
			putc('\n', fp);
			p0 += frame->linesize[0];
		}
		fflush(fp);
		fclose(fp);
	}
}