///> Include FFMpeg
#pragma once
#define _CRT_SECURE_NO_DEPRECATE
#pragma warning(disable:4996)

///> Include FFMpeg
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

#include <iostream>
using namespace std;
#define NUM 1000


extern "C" {
#include <libavformat/avformat.h>		// Basic Format manage header
#include <libavcodec/avcodec.h>			// For using codec header
#include <libavutil/avutil.h>			// AV Convenience header
#include <libavutil\imgutils.h>			// Img Convenience header
#include <libswscale/swscale.h>			// External API header
//#include <libavutil\timestamp.h>		// time Stamp
#include <libavformat/avio.h>			// Input & output header
#include <libavutil/opt.h>				// option header
#include <libavutil/mathematics.h>		// math header
#include <libswresample/swresample.h>	// Resample header
}

///> Library Link On Windows System
#pragma comment( lib, "avformat.lib" )   
#pragma comment( lib, "avutil.lib" )
#pragma comment( lib, "avcodec.lib" )

static void log_packet(const AVFormatContext *fmt_ctx, const AVPacket *pkt, const char *tag) {
	AVRational *time_base = &fmt_ctx->streams[pkt->stream_index]->time_base; 
	//printf("%s: pts:%s pts_time:%s dts:%s dts_time:%s duration:%s duration_time:%s stream_index:%d\n", tag, av_ts2str(pkt->pts), av_ts2timestr(pkt->pts, time_base), av_ts2str(pkt->dts), av_ts2timestr(pkt->dts, time_base), av_ts2str(pkt->duration), av_ts2timestr(pkt->duration, time_base), pkt->stream_index);
}


int main() {
	int argc;
	argc = 2;
	char **argv = new char*;
	argv[1] = "./Test_Video_2.ts";
	argv[2] = "./Remuxing_result.ts";
	AVOutputFormat *ofmt = NULL;  
	AVFormatContext *ifmt_ctx = NULL, *ofmt_ctx = NULL;  
	AVPacket pkt;   
	const char *in_filename, *out_filename;   
	int ret, i; 
	//if (argc < 3) { 
	//	printf("usage: %s input output\n"   
	//		"API example program to remux a media file with libavformat and libavcodec.\n"   
	//		"The output format is guessed according to the file extension.\n"       
	//		"\n", argv[0]); 
	//	return 1; 
	//}

	in_filename = argv[1];   
	out_filename = argv[2];

	av_register_all();

	// file open 후 Format 에 할당해줌
	if ((ret = avformat_open_input(&ifmt_ctx, in_filename, 0, 0)) < 0) {
		fprintf(stderr, "Could not open input file '%s'", in_filename);
		goto end;
	}    if ((ret = avformat_find_stream_info(ifmt_ctx, 0)) < 0) {
		fprintf(stderr, "Failed to retrieve input stream information");
		goto end;
	}

	// output context 할당
	av_dump_format(ifmt_ctx, 0, in_filename, 0);
	avformat_alloc_output_context2(&ofmt_ctx, NULL, NULL, out_filename);
	if (!ofmt_ctx) {
		fprintf(stderr, "Could not create output context\n");
		ret = AVERROR_UNKNOWN;
		goto end;
	}

	// output format 할당
	ofmt = ofmt_ctx->oformat;
	
	// 스트림을 저장함.
	for (i = 0; i < ifmt_ctx->nb_streams; i++) {
		// 스트림을 순서대로 불러옴
		AVStream *in_stream = ifmt_ctx->streams[i];
		// Out 스트림에 새롭게 만들어줌
		AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream->codec->codec);
		if (!out_stream) {
			fprintf(stderr, "Failed allocating output stream\n");
			ret = AVERROR_UNKNOWN;
			goto end;
		}

		// context를 copy 함
		ret = avcodec_copy_context(out_stream->codec, in_stream->codec);
		if (ret < 0) {
			fprintf(stderr, "Failed to copy context from input to output stream codec context\n");
			goto end;
		}
		if (ofmt_ctx->oformat->flags & AVFMT_GLOBALHEADER)
			out_stream->codec->flags |= CODEC_FLAG_GLOBAL_HEADER;
	}
	av_dump_format(ofmt_ctx, 0, out_filename, 1);
	if (!(ofmt->flags & AVFMT_NOFILE)) {
		ret = avio_open(&ofmt_ctx->pb, out_filename, AVIO_FLAG_WRITE);
		if (ret < 0) {
			fprintf(stderr, "Could not open output file '%s'", out_filename);
			goto end;
		}
	}    
	
	ret = avformat_write_header(ofmt_ctx, NULL);
	
	if (ret < 0) {
		fprintf(stderr, "Error occurred when opening output file\n");
		goto end;
	}

	while (1) {
		AVStream *in_stream, *out_stream;
		ret = av_read_frame(ifmt_ctx, &pkt);
		if (ret < 0)
			break;
		in_stream = ifmt_ctx->streams[pkt.stream_index];
		out_stream = ofmt_ctx->streams[pkt.stream_index];
		log_packet(ifmt_ctx, &pkt, "in");
		/* copy packet */
		AVRounding* AVR = new AVRounding;
		pkt.pts = av_rescale_q_rnd(pkt.pts, in_stream->time_base, out_stream->time_base, *AVR);
		pkt.dts = av_rescale_q_rnd(pkt.dts, in_stream->time_base, out_stream->time_base, *AVR);
		pkt.duration = av_rescale_q(pkt.duration, in_stream->time_base, out_stream->time_base);
		pkt.pos = -1;
		log_packet(ofmt_ctx, &pkt, "out");
		ret = av_interleaved_write_frame(ofmt_ctx, &pkt);
		if (ret < 0) {
			fprintf(stderr, "Error muxing packet\n");
			break;
		}
		av_free_packet(&pkt);
	}
	av_write_trailer(ofmt_ctx);

end:
	avformat_close_input(&ifmt_ctx);
	/* close output */
	if (ofmt_ctx && !(ofmt->flags & AVFMT_NOFILE))
		avio_close(ofmt_ctx->pb);
	avformat_free_context(ofmt_ctx);
	if (ret < 0 && ret != AVERROR_EOF) {
		//fprintf(stderr, "Error occurred: %s\n", av_err2str(ret));      
		return 1;
	}
	return 0;
}